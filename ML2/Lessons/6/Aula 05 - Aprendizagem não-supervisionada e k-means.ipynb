{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aula 05 - Aprendizagem não-supervisionada & k-means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Até o momento, neste modelo, já estudamos algumas aplicações de algoritmos do tipo *máquinas de vetores suporte* e vimos alguns métodos de *boosting*. Nestes casos, sempre sabíamos a que classe de dados pertenciam as amostras que gostaríamos de prever, no momento de treinamento dos modelos. Agora, vamos começar a discutir um outro âmbito da área de Aprendizado de Máquina: a **aprendizagem não-supervisionada!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para iniciar nossa discussão, vamos carregar um [conjunto de dados ilustrativo](https://www.kaggle.com/datasets/samuelcortinhas/time-series-practice-dataset) que traz séries temporais da venda de diversos produtos por algumas lojas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temos, assim, poucas colunas no nosso conjunto de dados. Vamos fazer um plot, para ter uma ideia dessas quantidades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"Date\")['number_sold'].mean().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([\"Date\", \"store\"])['number_sold'].mean().unstack().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([\"Date\", \"product\"])['number_sold'].mean().unstack().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir dessas visualizações, já conseguimos ter uma ideia de qual o comportamento dos nossos dados. Agora, vamos filtrar apenas um dos anos e tentar observar relações entre algumas variáveis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Date'] < '2011-01-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Date'] < '2011-01-01'].groupby([\"Date\", \"product\"])['number_sold'].mean().unstack().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data = df[df['Date'] < '2011-01-01'],\n",
    "               x = 'number_sold',\n",
    "               y = 'product')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pergunta:** a que corresponde cada um dos pontos no plot acima?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data = df[df['Date'] < '2011-01-01'],\n",
    "               x = 'number_sold',\n",
    "               y = 'product',\n",
    "               hue = 'store',\n",
    "               palette = 'mako')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quando adicionamos a informação de a que loja cada conjunto de pontos pertence, podemos entender bem melhor que **lojas específicas possuem faixas específicas de unidades vendidas para cada tipo de produto**. Possivelmente, isso é influenciado por vários fatores, como porte das lojas, capacidade de atrir clientes etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mas e se não soubéssemos, previamente, a que loja pertence cada um dos pontos acima? Será que seria possível tentar fazer essa inferência? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "____\n",
    "_____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aprendizagem não-supervisionada\n",
    "\n",
    "Chegamos ao nosso último tópico do módulo: **aprendizagem não-supervisionada (unsurpervised learning)**.\n",
    "\n",
    "Este tipo de aprendizagem se diferencia da aprendizagem supervisionada de modo muito simples: **os targets não fazem parte da base de dados!**\n",
    "\n",
    "> Na aprendizagem não-supervisionada, temos acesso apenas ao conjunto de features, $\\{\\vec{x}_i\\}_{i=1}^N$\n",
    "\n",
    "A perda que temos com relação à aprendizagem supervisionada é gigante: sem os targets, torna-se impossível a estimação do processo teórico $\\mathcal{F}$ que gerou os dados!\n",
    "\n",
    "Assim, o máximo que podemos fazer na aprendizagem não-supervisionada é a **determinação de estrutura nos dados**:\n",
    "\n",
    "<img src=https://www.researchgate.net/profile/Zhenyu-Wen-2/publication/336642133/figure/fig3/AS:815304842170368@1571395230317/Examples-of-Supervised-Learning-Linear-Regression-and-Unsupervised-Learning.png width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em um problema de classificação, somos capazes de encontrar a fronteira de decisão dentre as classes que **são conhecidas no treino**:\n",
    "\n",
    "<img src=https://s3-sa-east-1.amazonaws.com/lcpi/f29c8ebf-dd5f-4fce-99bb-86ec8af21f51.PNG width=700>\n",
    "\n",
    "Já em problemas não-supervisionados, o máximo que podemos fazer é encontrar a estrutura presente nos dados (e com maior dificuldade!)\n",
    "\n",
    "<img src=https://s3-sa-east-1.amazonaws.com/lcpi/0c7b530d-e74b-4886-9601-740d054aa166.PNG width=300>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para muitas aplicações, isso já é suficiente: basta saber que os dados estão estruturados (agrupados/segmentados), sendo o significado de cada grupo/segmento de menor interesse, ou facilmente estimado de outra forma; ou, então, determinar aspectos importantes das features por si só, sem qualquer preocupação com o target.\n",
    "\n",
    "Neste curso, veremos dois grandes grupos de **técnicas não-supervisionadas**:\n",
    "\n",
    "- Clusterização - forma de encontrar grupos (clusters) nos dados;\n",
    "- Redução de dimensionalidade - importante processo de pré-processamento que visa reduzir o número de dimensões (features) de um dataset.\n",
    "\n",
    "Na aula de hoje, veremos técnicas de clusterização!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______\n",
    "\n",
    "### Clusterização\n",
    "\n",
    "Este tipo de problema consiste em __agrupar__ itens semelhantes, isto é, criar __grupos__ (ou __clusters__) dos dados que são parecidos entre si.\n",
    "\n",
    "> O objetivo central é **dividir os dados em grupos distintos**, tais que **membros de cada grupo sejam similares entre si**\n",
    "\n",
    "Problemas como estes podem aparecer em diversos contextos:\n",
    "\n",
    "- Identificação de tipos de clientes parecidos, para o direcionamento de marketing;\n",
    "- Agrupamento de cidades próximas para melhor logística de entrega de produtos;\n",
    "- Identificação de padrões climáticos;\n",
    "- Identificação de genes relacionados à determinada doença;\n",
    "- Identificação de documentos semelhantes em processos legais;\n",
    "\n",
    "...e qualquer outro problema em que você deseje **agrupar dados similares** ou ainda **encontrar alguma estrutura nos seus dados!**, mas tudo isso no que diz respeito ùnicamente **às features**!\n",
    "\n",
    "Veremos agora um dos principais algoritmos de clusterização, o **k-means**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "___\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means\n",
    "\n",
    "Documentação: [clique aqui!](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans)\n",
    "\n",
    "O k-means é utilizado para a determinação de um número **$k$ de clusters em nossos dados** (mais abaixo explicamos melhor como este algoritmo funciona!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para começar a entender um pouco melhor o algoritmo, vamos trabalhar, neste primeiro momento, **com um exemplo ilustrativo**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T00:06:37.731037Z",
     "start_time": "2022-03-05T00:06:37.017447Z"
    }
   },
   "outputs": [],
   "source": [
    "# geração dos dados\n",
    "from sklearn.datasets import make_blobs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X, _ = make_blobs(n_samples = 300,\n",
    "                 n_features = 2,\n",
    "                 centers = 4,\n",
    "                 cluster_std = 1,\n",
    "                 random_state = 42)\n",
    "\n",
    "plt.scatter(X[:,0], X[:,1])\n",
    "plt.xlabel(\"X1\")\n",
    "plt.ylabel(\"X2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O primeiro passo pra aplicar o $k$-means é:\n",
    "\n",
    "- Determinar o número $k$ de clusters!\n",
    "\n",
    "Por exemplo, só de olhar pros dados plotados a seguir, fica fácil de identificar 4 grupos distintos, não é mesmo? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T00:06:37.793003Z",
     "start_time": "2022-03-05T00:06:37.739037Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(X, columns = \"x1 x2\".split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Mas, como o computador pode identificar estes grupos? É isso que o algoritmo responde!\n",
    "\n",
    "Uma vez determinado o número k de clusters, podemos construir nosso modelo!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construindo o modelo\n",
    "\n",
    "Note que temos apenas as **features** dos dados (no caso, $x_1$ e $x_2$). Iso caracteriza um problema de clusterização **não-supervisionado**: quando nossos dados **não têm targets**, apenas features!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T00:06:38.782122Z",
     "start_time": "2022-03-05T00:06:37.801015Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temos vários argumentos na classe, mas os principais são:\n",
    "\n",
    ">- n_clusters: quantos clusters queremos (o número k);\n",
    "\n",
    ">- max_iter: é o número máximos de iterações que o algoritmo fará, se ele não convergir antes disso. É uma boa ideia não colocar um número tão grande, ou o algoritmo pode ficar bem lento. Algo da ordem de 1000, em geral é uma boa escolha.\n",
    "\n",
    "Por fim, pra fitar o modelo, fazemos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T00:06:38.811093Z",
     "start_time": "2022-03-05T00:06:38.792106Z"
    }
   },
   "outputs": [],
   "source": [
    "# da figura, queremos 4 clusters\n",
    "kmeans = KMeans(n_clusters = 4, n_init = 'auto')\n",
    "kmeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em algoritmos **não supervisionados**, não existe a divisão em dados de treino e dados de teste, porque **não há o que testar!**. Queremos apenas **econtrar estrutura** nos dados!\n",
    "\n",
    "Então, basta fitar o modelo com nossos dados todos (no caso, o array X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T00:06:39.146580Z",
     "start_time": "2022-03-05T00:06:38.815088Z"
    }
   },
   "outputs": [],
   "source": [
    "kmeans.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que o modelo está treinado, podemos fazer predições:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T00:06:39.186549Z",
     "start_time": "2022-03-05T00:06:39.161567Z"
    }
   },
   "outputs": [],
   "source": [
    "kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T00:06:39.876486Z",
     "start_time": "2022-03-05T00:06:39.194550Z"
    }
   },
   "outputs": [],
   "source": [
    "kmeans.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T00:06:39.891480Z",
     "start_time": "2022-03-05T00:06:39.880485Z"
    }
   },
   "outputs": [],
   "source": [
    "labels_clusters = kmeans.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Isto retorna uma lista com número de elementos igual ao número de pontos do dataset, e com valores entre 0 e k-1, indicando qual é o número do cluster (a contagem começa com zero). \n",
    "\n",
    "No nosso caso, como k = 4, teremos os clusters 0, 1, 2 e 3.\n",
    "\n",
    "Pra visualizarmos os clusters, basta plotar os dados iniciais com o hue adequado!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T00:06:39.986426Z",
     "start_time": "2022-03-05T00:06:39.908487Z"
    }
   },
   "outputs": [],
   "source": [
    "X_df = pd.DataFrame(X, columns = \"x1 x2\".split())\n",
    "labels_series = pd.Series(labels_clusters, name = \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T00:06:40.080373Z",
     "start_time": "2022-03-05T00:06:39.992422Z"
    }
   },
   "outputs": [],
   "source": [
    "df_result = pd.concat([X_df, labels_series], axis = 1)\n",
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T00:06:40.188312Z",
     "start_time": "2022-03-05T00:06:40.083370Z"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.scatterplot(data = df_result,\n",
    "               x = 'x1',\n",
    "               y = 'x2',\n",
    "               hue = 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T00:06:42.368894Z",
     "start_time": "2022-03-05T00:06:40.192309Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.jointplot(data = df_result, x = 'x1', y = 'x2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T00:06:45.709011Z",
     "start_time": "2022-03-05T00:06:42.376891Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.jointplot(data = df_result, x = 'x1', y = 'x2', hue = 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# geração dos dados\n",
    "from sklearn.datasets import make_blobs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X, _ = make_blobs(n_samples = 300,\n",
    "                 n_features = 2,\n",
    "                 centers = 4,\n",
    "                 cluster_std = 2.5,\n",
    "                 random_state = 42)\n",
    "\n",
    "plt.scatter(X[:,0], X[:,1])\n",
    "plt.xlabel(\"X1\")\n",
    "plt.ylabel(\"X2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters = 4, n_init = 'auto')\n",
    "kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.fit(X)\n",
    "kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters = 4, n_init = 'auto') # inicialização\n",
    "kmeans.fit(X) # fit dos dados\n",
    "\n",
    "# plotando o resultado\n",
    "X_df = pd.DataFrame(X, columns = \"x1 x2\".split())\n",
    "labels_clusters = kmeans.labels_\n",
    "labels_series = pd.Series(labels_clusters, name = \"label\")\n",
    "df_result = pd.concat([X_df, labels_series], axis = 1)\n",
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(data = df_result, x = 'x1', y = 'x2', hue = 'label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na prática, a análise segue de maneira qualitativa, inspecionando os clusters individuais:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T00:06:45.770003Z",
     "start_time": "2022-03-05T00:06:45.716990Z"
    }
   },
   "outputs": [],
   "source": [
    "df_result.query(\"label == 0\").describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T00:06:45.878896Z",
     "start_time": "2022-03-05T00:06:45.776956Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.jointplot(data = df_result.query(\"label == 0\"), x = 'x1', y = 'x2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determinando o $k$\n",
    "\n",
    "Mas e se não for tão fácil de plotar os dados para determinar o $k$?\n",
    "\n",
    "Pode ser que não consigamos visualizar nossos dados em 2D, se, por exemplo, tivermos mais de 2 features em nossos dados...\n",
    "\n",
    "> Quase sempre, uma boa metodologia para a determinaçãodo número de clusters é **conhecimento do negócio**! Muitas vezes, o próprio problema nos indica a quantidade de clusters que esperamos encontrar!\n",
    "\n",
    "No entanto, há situações em que o número de clusters não é conhecido a priori.\n",
    "\n",
    "Neste caso, podemos usar o __método do cotovelo__, que consiste em rodar o k-means várias vezes, para diferentes valores de k, e depois plotar um gráfico com a **inércia** de cada uma das rodadas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inércia (WCSS) e método do cotovelo\n",
    "\n",
    "A inércia também é chamada de **WCSS** (Within-Cluster-Sum-of-Squares), isto é, \"soma de quadrados intra-cluster\", que é calculada como a soma das distâncias (ao quadrado) entre os pontos e os centróides dos clusters.\n",
    "\n",
    "Quanto menor o WCSS, mais eficiente foi a clusterização, **mas até certo ponto!**\n",
    "\n",
    "Conforme o número de clusters ($k$) aumenta, o WCSS diminui, sendo mínimo quando cada ponto é seu próprio cluster isolado (o que não é nada útil, pois se cada ponto for um cluster, não há clusterização alguma!).\n",
    "\n",
    "Assim, o que queremos não é encontrar um $k$ que minimize o WCSS, mas sim um k a partir do qual o WCSS **para de decrescer tão rapidamente!**\n",
    "\n",
    "Quando encontramos este $k$, encontramos o número ideal de clusters!\n",
    "\n",
    "Ao plotarmos o WCSS (inércia) em função de $k$, o que buscaremos será então o valor de $k$ após o qual **o gráfico deixa de ser tão inclinado**. Esses pontos são visualizados como \"quinas\", ou **cotovelos** no gráfico -- e daí vem o nome do método!\n",
    "\n",
    "Para aplicar o método, fazemos:\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T00:06:46.981322Z",
     "start_time": "2022-03-05T00:06:46.966329Z"
    }
   },
   "outputs": [],
   "source": [
    "kmeans.inertia_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos, agora, escrever uma função para calcular a inércia para vários valores de *k*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T00:08:48.979469Z",
     "start_time": "2022-03-05T00:08:48.966475Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# geração dos dados\n",
    "from sklearn.datasets import make_blobs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X, _ = make_blobs(n_samples = 300,\n",
    "                 n_features = 2,\n",
    "                 centers = 4,\n",
    "                 cluster_std = 1,\n",
    "                 random_state = 42)\n",
    "\n",
    "plt.scatter(X[:,0], X[:,1])\n",
    "plt.xlabel(\"X1\")\n",
    "plt.ylabel(\"X2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T00:06:47.263204Z",
     "start_time": "2022-03-05T00:06:47.102249Z"
    }
   },
   "outputs": [],
   "source": [
    "def calc_inercias(X, lista_k, plot=True):\n",
    "    lista_inercias = []\n",
    "    \n",
    "    X_df = pd.DataFrame(X, columns = [f\"X{i+1}\" for i in range(X.shape[1])])\n",
    "    \n",
    "    for k in lista_k:\n",
    "        kmeans = KMeans(n_clusters = k)\n",
    "        kmeans.fit(X)\n",
    "        \n",
    "        labels_clusters = kmeans.labels_\n",
    "        \n",
    "        # Cálculo das inércias\n",
    "        inercia = kmeans.inertia_\n",
    "        lista_inercias.append(inercia)\n",
    "        \n",
    "        labels_series = pd.Series(labels_clusters, name = 'label')\n",
    "        df_result = pd.concat([X_df, labels_series], axis = 1)\n",
    "        \n",
    "        # Vamos, também, plotar como ficam os agrupamentos\n",
    "        if plot and X.shape[1] == 2:\n",
    "            print(f\"\\nInércia para clusterização com k = {k}: {inercia}\")\n",
    "            \n",
    "            sns.jointplot(data = df_result,\n",
    "                        x = 'X1',\n",
    "                        y = 'X2',\n",
    "                        hue = 'label')\n",
    "            plt.show()\n",
    "    return lista_inercias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T00:07:03.640265Z",
     "start_time": "2022-03-05T00:06:47.267198Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inercias = calc_inercias(X, [1, 2, 3, 4, 5, 6, 7, 8], plot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T00:07:03.655254Z",
     "start_time": "2022-03-05T00:07:03.642260Z"
    }
   },
   "outputs": [],
   "source": [
    "inercias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T00:07:03.764198Z",
     "start_time": "2022-03-05T00:07:03.697229Z"
    }
   },
   "outputs": [],
   "source": [
    "# função para plotar as inércias\n",
    "def plot_cotovelo(lista_k, lista_inercias):\n",
    "    plt.figure(figsize=(8,5))\n",
    "    \n",
    "    plt.title('Método do cotovelo')\n",
    "    plt.plot(lista_k, lista_inercias, marker = \"o\")\n",
    "    \n",
    "    plt.xlabel(\"k\")\n",
    "    plt.ylabel(\"Inércia (WCSS)\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linspace(1,8,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T00:07:04.382417Z",
     "start_time": "2022-03-05T00:07:03.772187Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "plot_cotovelo(list(np.linspace(1,8,8)), inercias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T00:07:04.397408Z",
     "start_time": "2022-03-05T00:07:04.385416Z"
    }
   },
   "outputs": [],
   "source": [
    "# geração dos dados\n",
    "from sklearn.datasets import make_blobs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X, _ = make_blobs(n_samples = 300,\n",
    "                 n_features = 2,\n",
    "                 centers = 4,\n",
    "                 cluster_std = 2.5,\n",
    "                 random_state = 42)\n",
    "\n",
    "plt.scatter(X[:,0], X[:,1])\n",
    "plt.xlabel(\"X1\")\n",
    "plt.ylabel(\"X2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inercias = calc_inercias(X, [1, 2, 3, 4, 5, 6, 7, 8], plot = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T00:07:07.489837Z",
     "start_time": "2022-03-05T00:07:04.404407Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_cotovelo(list(np.linspace(1,8,8)), inercias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O valor de $k$ mais adequado é aquele em que o gráfico tem uma \"quina\" bem abrupta: no exemplo acima, $k = 4$, como já sabíamos!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______\n",
    "\n",
    "### Método da silhueta\n",
    "\n",
    "Um método alternativo ao método do cotovelo para o cálculo do número adequado de clusters é o método da silhueta.\n",
    "\n",
    "Neste método, é calculado para cada ponto um score conhecido como **coeficiente de silhueta**, que é dado por:\n",
    "\n",
    "$$ s = \\frac{b - a}{max(a, b)} $$\n",
    "\n",
    "onde:\n",
    "\n",
    "- $a$ é a **distância média entre um dado ponto e os pontos de seu próprio cluster**. Portanto, essa é uma medida de **similaridade entre um ponto e seu cluster**;\n",
    "- $b$ é a **distância média entre um dado ponto e os pontos do cluster mais próximo (sem ser o próprio).** Portanto, essa é uma medida de **dissimilaridade entre um ponto e os demais clusters**;\n",
    "\n",
    "Graficamente:\n",
    "\n",
    "<img src=https://miro.medium.com/max/712/1*cUcY9jSBHFMqCmX-fp8BvQ.jpeg width=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note que $-1 < s < 1$, sendo mais próximo de $1$ quando um ponto está no cluster correto ($a \\ll b$); e mais próximo de $-1$ quando um ponto está no custer errado ($b \\gg a$).\n",
    "\n",
    "Na prática, é costumeiro olhar para **a média do coeficiente $s$ para todos os pontos, denotado $\\bar{s}$**, e apresentar uma única métrica. A ideia é que se, em média, tivermos pontos em clusters corretos, teremos $\\bar{s} \\rightarrow 1$; enquanto, se em média tivermos muitos pontos em clusters incorretos, teremos $\\bar{s} \\rightarrow -1$.\n",
    "\n",
    "Este score é calculado com a função [silhouette_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_score.html) do sklearn.\n",
    "\n",
    "Uma vez que é possível calcularmos o score para um dado $k$, a decisão sobre o melhor $k$ segue similar ao método do cotovelo: basta calcular o score de silhueta para vários valores de $k$, e selecionar aquele que dá **a silueta mais próxima de $1$**!\n",
    "\n",
    "Vamos fazer isso, abaixo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T00:19:28.133977Z",
     "start_time": "2022-03-05T00:19:28.105989Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "def calc_silhueta(X, lista_k, plot = True):\n",
    "    lista_silhuetas = []\n",
    "    \n",
    "    X_df = pd.DataFrame(X, columns = [f\"X{i+1}\" for i in range(X.shape[1])])\n",
    "    \n",
    "    for k in lista_k:\n",
    "        kmeans = KMeans(n_clusters = k)\n",
    "        kmeans.fit(X)\n",
    "        \n",
    "        labels_clusters = kmeans.labels_\n",
    "        \n",
    "        # Cálculo das silhuetas\n",
    "        silhueta = silhouette_score(X, labels_clusters)\n",
    "        lista_silhuetas.append(silhueta)\n",
    "        \n",
    "        labels_series = pd.Series(labels_clusters, name = 'label')\n",
    "        df_result = pd.concat([X_df, labels_series], axis = 1)\n",
    "        \n",
    "        # Vamos, também, plotar como ficam os agrupamentos\n",
    "        if plot and X.shape[1] == 2:\n",
    "            print(f\"\\nSilueta média para clusterização com k = {k}: {silhueta}\")\n",
    "            \n",
    "            sns.jointplot(data = df_result,\n",
    "                        x = 'X1',\n",
    "                        y = 'X2',\n",
    "                        hue = 'label')\n",
    "            plt.show()\n",
    "    return lista_silhuetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T00:07:09.450213Z",
     "start_time": "2022-03-05T00:07:07.528815Z"
    }
   },
   "outputs": [],
   "source": [
    "lista_k = range(2,9)\n",
    "\n",
    "lista_silhuetas = calc_silhueta(X, lista_k, plot = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T00:07:09.481201Z",
     "start_time": "2022-03-05T00:07:09.459208Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_silhueta(X, lista_k):\n",
    "    \n",
    "    lista_silhuetas = calc_silhueta(X, lista_k, plot=False)\n",
    "\n",
    "    plt.figure(figsize=(8, 5))\n",
    "\n",
    "    plt.title(\"Método da silhueta\")\n",
    "\n",
    "    plt.plot(lista_k, lista_silhuetas, marker=\"o\")\n",
    "\n",
    "    plt.xlabel(\"k (# de clusters)\")\n",
    "    plt.ylabel(\"Mean silhouette score\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T00:07:11.653305Z",
     "start_time": "2022-03-05T00:07:09.503025Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_silhueta(X, lista_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data = X_df,\n",
    "               x = 'x1',\n",
    "               y = 'x2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui novamente, fica claro que o ideal é $k=3$!\n",
    "\n",
    "Para entender o porquê do método receber o nome \"silhueta\", podemos utilizar o seguinte código do sklearn, [que tirei daqui!](https://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_silhouette_analysis.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T00:07:15.485081Z",
     "start_time": "2022-03-05T00:07:11.658301Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "range_n_clusters = [2, 3, 4, 5, 6]\n",
    "\n",
    "for n_clusters in range_n_clusters:\n",
    "    \n",
    "    # Create a subplot with 1 row and 2 columns\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    fig.set_size_inches(18, 7)\n",
    "\n",
    "    # The 1st subplot is the silhouette plot\n",
    "    # The silhouette coefficient can range from -1, 1 but in this example all\n",
    "    # lie within [-0.1, 1]\n",
    "    ax1.set_xlim([-0.1, 1])\n",
    "    # The (n_clusters+1)*10 is for inserting blank space between silhouette\n",
    "    # plots of individual clusters, to demarcate them clearly.\n",
    "    ax1.set_ylim([0, len(X) + (n_clusters + 1) * 10])\n",
    "\n",
    "    # Initialize the clusterer with n_clusters value and a random generator\n",
    "    # seed of 10 for reproducibility.\n",
    "    clusterer = KMeans(n_clusters=n_clusters, random_state=10)\n",
    "    cluster_labels = clusterer.fit_predict(X)\n",
    "\n",
    "    # The silhouette_score gives the average value for all the samples.\n",
    "    # This gives a perspective into the density and separation of the formed\n",
    "    # clusters\n",
    "    silhouette_avg = silhouette_score(X, cluster_labels)\n",
    "    \n",
    "    # Compute the silhouette scores for each sample\n",
    "    sample_silhouette_values = silhouette_samples(X, cluster_labels)\n",
    "\n",
    "    y_lower = 10\n",
    "    \n",
    "    for i in range(n_clusters):\n",
    "        # Aggregate the silhouette scores for samples belonging to\n",
    "        # cluster i, and sort them\n",
    "        ith_cluster_silhouette_values = sample_silhouette_values[cluster_labels == i]\n",
    "\n",
    "        ith_cluster_silhouette_values.sort()\n",
    "\n",
    "        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "        y_upper = y_lower + size_cluster_i\n",
    "\n",
    "        color = cm.nipy_spectral(float(i) / n_clusters)\n",
    "        ax1.fill_betweenx(np.arange(y_lower, y_upper),\n",
    "                          0, ith_cluster_silhouette_values,\n",
    "                          facecolor=color, edgecolor=color, alpha=0.7)\n",
    "\n",
    "        # Label the silhouette plots with their cluster numbers at the middle\n",
    "        ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "\n",
    "        # Compute the new y_lower for next plot\n",
    "        y_lower = y_upper + 10  # 10 for the 0 samples\n",
    "\n",
    "    ax1.set_title(\"The silhouette plot for the various clusters.\")\n",
    "    ax1.set_xlabel(\"The silhouette coefficient values\")\n",
    "    ax1.set_ylabel(\"Cluster label\")\n",
    "\n",
    "    # The vertical line for average silhouette score of all the values\n",
    "    ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
    "\n",
    "    ax1.set_yticks([])  # Clear the yaxis labels / ticks\n",
    "    ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "\n",
    "    # 2nd Plot showing the actual clusters formed\n",
    "    colors = cm.nipy_spectral(cluster_labels.astype(float) / n_clusters)\n",
    "    ax2.scatter(X[:, 0], X[:, 1], marker='.', s=30, lw=0, alpha=0.7,\n",
    "                c=colors, edgecolor='k')\n",
    "\n",
    "    # Labeling the clusters\n",
    "    centers = clusterer.cluster_centers_\n",
    "    # Draw white circles at cluster centers\n",
    "    ax2.scatter(centers[:, 0], centers[:, 1], marker='o',\n",
    "                c=\"white\", alpha=1, s=200, edgecolor='k')\n",
    "\n",
    "    for i, c in enumerate(centers):\n",
    "        ax2.scatter(c[0], c[1], marker='$%d$' % i, alpha=1,\n",
    "                    s=50, edgecolor='k')\n",
    "\n",
    "    ax2.set_title(\"The visualization of the clustered data.\")\n",
    "    ax2.set_xlabel(\"Feature space for the 1st feature\")\n",
    "    ax2.set_ylabel(\"Feature space for the 2nd feature\")\n",
    "\n",
    "    title = \"Silhouette analysis for KMeans clustering on sample data \"\n",
    "    title += \"with n_clusters = {}\\nSilhouette score = {:.2f}\".format(n_clusters, silhouette_avg)\n",
    "    plt.suptitle(title, fontsize=14, fontweight='bold')\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na prática, é recomendável usar ambos os métodos, do cotovelo e da silhueta, pra apoiar a tomada de decisão quanto ao valor adequado de $k$.\n",
    "\n",
    "No entanto, lembre-se: sempre que possível, guie esta decisão segundo o contexto do problema de negócio!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vamos fazer um exemplo com mais features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T00:11:03.478562Z",
     "start_time": "2022-03-05T00:11:03.460573Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "X_new, _ = make_blobs(n_samples = 500,\n",
    "                     n_features = 4,\n",
    "                     centers = 6,\n",
    "                     cluster_std = 1,\n",
    "                      random_state = 0\n",
    "                     )\n",
    "df = pd.DataFrame(X_new, columns = [f\"X{i+1}\" for i in range(X_new.shape[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T00:11:09.028068Z",
     "start_time": "2022-03-05T00:11:09.007076Z"
    }
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T00:08:24.434390Z",
     "start_time": "2022-03-05T00:08:20.054797Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.pairplot(data = df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusão:** muito difícil de escolher o $k$ com base em análise exploratória!\n",
    "\n",
    "Aí, não tem jeito, temos que utilizar os métodos quantitativos do cotovelo e/ou silhueta!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aplicando o método do cotovelo...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T00:09:06.506959Z",
     "start_time": "2022-03-05T00:09:05.335635Z"
    }
   },
   "outputs": [],
   "source": [
    "inercias = calc_inercias(X_new, range(2,11))\n",
    "plot_cotovelo(range(2,11), inercias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aplicando o método da silhueta...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T00:08:37.763533Z",
     "start_time": "2022-03-05T00:08:36.339709Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_silhueta(X_new, range(2,11))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vamos tentar separadamente $k=6$**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T00:15:32.427026Z",
     "start_time": "2022-03-05T00:15:19.587568Z"
    }
   },
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters = 6)\n",
    "kmeans.fit(X_new)\n",
    "\n",
    "labels = kmeans.labels_\n",
    "X_new_df = pd.DataFrame(X_new, columns = [f\"X{i+1}\" for i in range(X_new.shape[1])])\n",
    "dados_clusterizados = pd.concat([X_new_df, \n",
    "                                 pd.Series(labels, name = 'clusters')],\n",
    "                               axis = 1)\n",
    "\n",
    "sns.pairplot(data = dados_clusterizados,\n",
    "            hue = 'clusters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As projeções em duas dimensões mostram que $k=6$ de fato é a melhor escolha! (O que faz sentido, pois nossos dados artificiais foram preparados para conter 6 clusters!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E como o k-means funciona?\n",
    "\n",
    "Uma vez escolhido o número de clusters, o k-means segue as seguintes etapas:\n",
    "\n",
    "- 1) k pontos são escolhidos aleatoriamente como sendo os centroides dos clusters (centroide é o centro do cluster);\n",
    "\n",
    "- 2) Para cada ponto, vamos calcular qual é a distância entre ele e os k centroides. Aquele centroide que estiver mais perto, será o cluster ao qual este ponto pertencerá. Fazemos isso para todos os pontos!\n",
    "\n",
    "- 3) Ao fim do passo 2, teremos k clusters, cada um com seu centroide, e todos os pontos pertencerão a determinado cluster!\n",
    "\n",
    "- 4) Uma vez que temos os clusters, calculamos qual é de fato o centro de cada um deles. Isso é feito tomando a média da posição de todos os pontos;\n",
    "\n",
    "- 5) Após determinar os novos k centroides, repetimos o processo!\n",
    "\n",
    "- 6) E o processo se repete até que os centroides não mudem mais. Quando esta convergência for alcançada (ou após o número determinado de iterações), o algoritmo termina!\n",
    "\n",
    "<img src=\"https://stanford.edu/~cpiech/cs221/img/kmeansViz.png\" width=700>\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/1280/1*rwYaxuY-jeiVXH0fyqC_oA.gif\" width=500>\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/670/1*JUm9BrH21dEiGpHg76AImw.gif\" width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Quando uso algoritmos de clusterização, e em que casos eles não são uma boa ideia?**\n",
    "\n",
    "\n",
    "De certa fora, algoritmos de clusterização podem ser vistos como classificadores, uma vez que os clusters podem caracterizar um grupo, ou uma classe.\n",
    "\n",
    "No entanto, há uma diferença bem importante entre problemas de classificação e clusterização:\n",
    "\n",
    "- **Problemas de classificação** são **supervisionados**, isto é, as amostras de treino que utilizamos têm tanto as features como os **targets**. Em outras palavras, neste tipo de problema, sabemos de antemão quais são as classes de interesse - Isto é, temos $\\{\\vec{x}_i, y_i \\}_{i=1}^N$; <br><br>\n",
    "\n",
    "- **Problemas de clusterização**, por outro lado, são **não-supervisionados**. Ou seja, a amostra **não contêm** targets, temos apenas as features! O nosso objetivo é justamente descobrir **alguma estrutura de agrupamento** nos dados, mas sem qualquer informação prévia quanto aos grupos a serem formados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Foi exatamente o caso do nosso exemplo: nós tínhamos apenas as **features** dos dados, e **nenhuma** informação quanto aos grupos que seriam formados.\n",
    "\n",
    "Foi só depois que fizemos a análise exploratória dos dados (plot), que pudemos identificar alguma estrutura (4 clusters), para então aplicar o k-means!\n",
    "\n",
    "No segundo caso, só pudemos determinar o número de clusters de forma segura utilizando o **método do cotovelo**.\n",
    "\n",
    "Assim sendo, via de regra, a utilização ou não de algoritmos de clusterização, além do tipo de problema, depende dos **dados disponíveis**!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Além do k-means, há outros algoritmos de clusterização que são muito utilizados, e que se baseiam em princípios bem diferentes do k-means.\n",
    "\n",
    "Na aula que vem, olharemos para um algoritmo bem importante: [DBSCAN](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html#sklearn.cluster.DBSCAN)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "____\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemplo real\n",
    "\n",
    "Vamos agora ver o KMeans aplicado a um problema e dataset real!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primeiro dataset -> classificação de tipos de vinho a partir da composição química.\n",
    "[Link para o dataset](https://archive.ics.uci.edu/ml/datasets/wine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_data = pd.read_csv('wine_data.csv')\n",
    "wine_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_data.Class.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A coluna 'Class' nos fornece o tipo do vinho, isso é o que queremos fazer com nosso modelo, por isso, vamos remover essa coluna e salvá-la para analisar os resultados obtidos pelo algoritmo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resposta = wine_data['Class']\n",
    "wine_data.drop(columns = ['Class'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resposta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É possível notar que cada coluna tem valores numéricos com proporções distintas, como o algoritmo funciona medindo distâncias, é melhor que os dados estejam num mesmo alcance (de 0 a 1 por exemplo). Como sabemos, o sklearn tem um algoritmo de préprocessamento que faz isso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "transformed_wine = scaler.fit_transform(wine_data)\n",
    "transformed_wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (13,8))\n",
    "sns.heatmap(wine_data.corr(), annot = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora com os valores entre 0 e 1 vamos instanciar o modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data = wine_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inercias = calc_inercias(transformed_wine, range(2,11))\n",
    "plot_cotovelo(range(2,11), inercias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_silhueta(transformed_wine, range(2,11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transform = pd.DataFrame(transformed_wine, columns = wine_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimador = KMeans(n_clusters = 3, random_state = 42)\n",
    "modelo = estimador.fit(df_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ou, podemos usar o .predict() como já estamos acostumados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo.predict(df_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transform['cluster'] = modelo.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transform.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data = df_transform, hue = 'cluster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transform.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data = df_transform,\n",
    "               x = 'Alcohol',\n",
    "               y = 'Color intensity',\n",
    "               hue = 'cluster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resposta[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transform['cluster'][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = df_transform[df_transform['cluster'] == 1]['cluster'].index\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resposta[idx].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resposta[165:177]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transform['classe'] = df_transform['cluster']\n",
    "df_transform.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# vamos contar quantas classificações erradas teríamos?\n",
    "df_transform.loc[df_transform['cluster'] == 0, 'classe'] = 2\n",
    "df_transform.loc[df_transform['cluster'] == 1, 'classe'] = 3\n",
    "df_transform.loc[df_transform['cluster'] == 2, 'classe'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_transform.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(abs(resposta - df_transform['classe']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transform.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "9/df_transform.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com isso conseguimos ver quantas vezes nosso modelo errou, dado que eram 178 dados inicialmente. Assim, podemos refletir se precisávamos de mais informações para realizar um cluster melhor ou se o agrupamento correto não apresentava a simetria radial que o KMeans traz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "Será que o método do K-means funcionaria bem para o dataset do início da aula? Fica como exercício!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
