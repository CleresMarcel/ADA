{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aula 6 - DBSCAN\n",
    "\n",
    "Agora que já começamos a nos familiarizar com a aprendizagem não supervisionada e com o K-Means, na aula de hoje, vamos avaliar um novo método para clusterização: o **DBSCAN**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"https://scikit-learn.org/stable/_images/sphx_glr_plot_cluster_comparison_001.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/auto_examples/cluster/plot_cluster_comparison.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "____\n",
    "_____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veja, abaixo, uma figura com um exemplo ilustrativo da diferença de clusterização entre o K-Means e o DSBCAN. Você consegue imaginar motivos pelos quais surgem essas diferenças nos grupos de pontos no espaço de atributos?\n",
    "\n",
    "<img src = \"https://miro.medium.com/v2/resize:fit:4800/format:webp/1*rfi9uHjGPdNgXgxe9xWvVw.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DBSCAN\n",
    "\n",
    "O DBSCAN é um algoritmo de clusterização baseado no conceito de **densidade**.\n",
    "\n",
    "O nome do algoritmo é uma sigla, que explica bem seu funcionamento: **D**ensity-**B**ased **S**patial **C**lustering of **A**pplications with **N**oise.\n",
    "\n",
    "O algoritmo foi proposto com o objetivo de proporcionar uma técnica de clusterização que possa funcionar **mesmo quando os clusters a serem criados não forem uniformes**, tendo **tamanho, forma e densidade variáveis**. \n",
    "\n",
    "Além disso, por construção o método funciona bem em contextos em que há **ruídos/outliers**, sendo capaz de detectá-los sem influenciar a criação dos clusters. \n",
    "\n",
    "Por fim, uma vantagem enorme é o fato do algoritmo **não demandar a determinação prévia da quantidade de clusters**, o que é uma vantagem interessante se não houver indicações do problema de negócio para esta determinação (embora, como veremos, ainda há hiperparâmetros importantes a serem determinados).\n",
    "\n",
    "Vamos entender o funcionamento do algoritmo mais a fundo!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"warning\" style='padding:0.1em; background-color:#E9D8FD; color:#69337A'>\n",
    "<span>\n",
    "<h2>Princípio de funcionamento</h2>\n",
    "<ul>\n",
    "<li>O DBSCAN tem como princípio fundamental a <b>determinação de regiões de alta densidade de observações</b>, que são <b>separadas entre si por regiões de baixa densidade</b>.\n",
    "</ul>\n",
    "</span>\n",
    "<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lembrando que, por ser um algoritmo não-supervisionado de clusterização, quando nos referimos a \"regiões\" cuja densidade será aferida, estamos nos referindo a regiões **do espaço de features**.\n",
    "\n",
    "Uma pergunta natural é: **como determinar a densidade de uma região?** Para responder a esta pergunta, precisamos de algumas definições:\n",
    "\n",
    "> **Densidade em um ponto $P$:** número de pontos dentro de um círculo de raio $\\epsilon$ centrado no ponto $P$ (região chamada de vizinhança-$\\epsilon$ de $P$);\n",
    "\n",
    "> **Região densa**: dizemos que uma região é densa se o círculo de raio $\\epsilon$ contém pelo menos um número mínimo de pontos (que chamaremos de $\\text{minPts}$. Uma região densa **formará um cluster**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para visualizar as definições acima, considere a figura a seguir:\n",
    "\n",
    "<img src=https://www.researchgate.net/publication/315326812/figure/fig2/AS:473095908663297@1489806262333/A-cluster-consists-of-core-points-red-and-border-points-green-Core-points-have-at.png width=500>\n",
    "\n",
    "<img src=https://www.researchgate.net/publication/335485895/figure/fig2/AS:797412515909651@1567129367940/A-single-DBSCAN-cluster-with-Core-Border-and-Noise-Points.ppm width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dada a definição acima, podemos classificar pontos dentro de um cluster como:\n",
    "\n",
    "> **Core points (pontos centrais)**: são pontos que estão no interior dos clusters (regiões densas). Matematicamente, um ponto é considerado core **se sua densidade é de pelo menos $\\text{minPts}$**, ou seja, se **há pelo menos $\\text{minPts}$ pontos dentro do círculo de raio $\\epsilon$ centrado no ponto**.\n",
    "\n",
    "> **Border points (pontos de fronteira)**: são pontos que estão na fronteira de um cluster. Matematicamente, estes pontos **têm densidade menor que $\\text{minPts}$**, mas que **fazem parte da vizinhança-$\\epsilon$ de um ponto central**.\n",
    "\n",
    "> **Noisy points (pontos de ruído/outliers)**: são pontos que não são centrais nem de fronteira. Estes pontos não fazem parte do cluster, e são considerados outliers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Olhando para as definições acima, e pras figuras, fica claro que $\\epsilon$ e $\\text{minPts}$ são os hiperparâmetros do modelo -- e que os clusters gerados são fortemente dependentes destes hiperparâmetros!\n",
    "\n",
    "\n",
    "> - $\\epsilon$ (`eps` no sklearn): determina o quão próximos (relativo a uma dada **métrica de distância**) os pontos devem estar entre si para serem considerados vizinhos, e, eventualmente, parte de um cluster. Na prática, **se a distância entre dois pontos for menor ou igual a $\\epsilon$, os pontos serão considerados vizinhos**;\n",
    "<br><br>\n",
    ">Se o valor de `eps` for muito pequeno, grande parte dos dados não serão clusterizados - muitos pontos serão considerados outliers, pois não haverá vizinhos suficientes para gerar uma região densa;<br><br>\n",
    ">Por outro lado, se o valor de `eps` for muito grande, os clusters se fundirão, e a maioria dos pontos estarão em um único, grande cluster.<br><br>\n",
    ">Portanto, a escolha de `eps` está muito relacionada com **a escala** das features, o que demanda cuidadosa análise exploratória.<br><br>\n",
    ">Além disso, note que o  `eps` depende também fortemente da **métrica de distância** (`metric` no sklearn) a ser utilizada.\n",
    "\n",
    "\n",
    "> - $\\text{minPts}$ (`min_samples` no sklearn): o número mínimo de pontos que devem ser vizinhos para formar uma região densa, que será um cluster.\n",
    "<br><br>\n",
    "Valores maiores de `min_samples` são preferíveis para datasets com outliers, formando clusters mais significativos (isto é, um cluster só será formado se realmente tiver uma alta densidade).\n",
    "\n",
    "Para algumas dicas práticas de como estimar bons valores para os hiper-parâmetros, [clique aqui](https://en.wikipedia.org/wiki/DBSCAN#Parameter_estimation).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "**Leitura complementar**\n",
    "\n",
    "[Understanding DBSCAN and implementation with python](https://towardsdatascience.com/understanding-dbscan-and-implementation-with-python-5de75a786f9f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__________\n",
    "\n",
    "Agora que entendemos os princípios e principais hiperparâmetros do DBSCAN, vamos agora nos atentar um pouco melhor aos passos de execução do algoritmo.\n",
    "\n",
    "> **Passo 1**: o algoritmo escolhe aleatoriamente um dos pontos, e sua vizinhança-$\\epsilon$ é calculada;\n",
    "\n",
    "> **Passo 2**: se este ponto tem $\\text{minPts}$ em sua vizinhança-$\\epsilon$, a formação do cluster é iniciada (veja próximo passo). Se não, o ponto é marcado como outlier (mas pode ser considerado como border point de um outro cluster posteriormente). Se for um outlier, volte ao passo 1;\n",
    "\n",
    "> **Passo 3**: se o ponto for um core point, todos os pontos na vizinhança são agregados ao cluster, e o passo 1 é aplicado a cada um deles;\n",
    "\n",
    "> **Passo 4**: o processo do passo 3 é continuado até que todos os pontos tenham um cluster associado ou esteja marcado como noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos visualizar a seguir o DBSCAN em funcionamento:\n",
    "\n",
    "\n",
    "<img src=\"http://data-analysis-stats.jp/wp-content/uploads/2019/09/DBSCAN_01.gif\" width=400>\n",
    "\n",
    "\n",
    "<img src=https://i.pinimg.com/originals/bb/3d/5e/bb3d5e522cbcb2dd07a81f8118de2041.gif width=500>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A classe do sklearn é esta: [DBSCAN](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, vamos avaliar duas situações, possibilitando comparações com o K-means:\n",
    "- a aplicação do DBSCAN em um dataset artificial, como fizemos na aula passada;\n",
    "- uma aplicação para clusterização de estações de metrô em São Paulo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DBSCAN na prática: dataset artificial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.datasets import make_blobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Geração de dados (como fizemos na última aula)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, _ = make_blobs(n_samples = 300,\n",
    "                 n_features = 2,\n",
    "                 centers = 4,\n",
    "                 cluster_std = 0.6,\n",
    "                 random_state = 0)\n",
    "\n",
    "plt.figure(figsize = (8,6))\n",
    "plt.scatter(X[:,0], X[:,1])\n",
    "plt.xlabel(\"X1\")\n",
    "plt.ylabel(\"X2\")\n",
    "\n",
    "plt.title(\"Espaço de features - X1 e X2 - dos dados artificiais\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como estamos lidando com distâncias, vamos normalizar as features de entrada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "X = StandardScaler().fit_transform(X)\n",
    "\n",
    "plt.figure(figsize = (8,6))\n",
    "plt.scatter(X[:,0], X[:,1])\n",
    "plt.xlabel(\"X1\")\n",
    "plt.ylabel(\"X2\")\n",
    "\n",
    "plt.title(\"Espaço de features - X1 e X2 - dos dados artificiais\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos, agora, colocar os dados em um dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = pd.DataFrame(X, columns = \"x1 x2\".split())\n",
    "X_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, vamos utilizar o [DBSCAN](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html) nos nossos dados para encontrar clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "dbscan = DBSCAN()\n",
    "dbscan.fit(X) # por padrão: eps = 0.5 e min_samples = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acessando os labels\n",
    "dbscan.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observação:** com o DBSCAN, dados considerados outliers/ruído (*noisy data*) são, por padrão, rotulados com $-1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarmente como fizemos para o K-means na última aula, vamos, agora, definir uma função para visualizar nossos agrupamentos para uma entrada específica dos parâmetros *eps* e *min_pts*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dbscan(X_df, eps, min_pts):\n",
    "     # Instanciamento e fit do modelo\n",
    "    dbscan = DBSCAN(eps = eps, min_samples = min_pts)\n",
    "    dbscan.fit(X_df)\n",
    "\n",
    "    # ========================================\n",
    "    # estruturação dos resultados\n",
    "    labels_clusters = dbscan.labels_\n",
    "    labels_series = pd.Series(labels_clusters, name=\"label\")\n",
    "\n",
    "    df_result = pd.concat([X_df, labels_series], axis=1)\n",
    "    n_clusters = pd.Series(labels_clusters).nunique()\n",
    "\n",
    "    # ========================================\n",
    "    print(f\"DBSCAN com eps={eps} e minPts={min_pts}\\nNúmero de clusters: {n_clusters}\")\n",
    "    sns.jointplot(data=df_result, x=\"x1\", y=\"x2\", hue=\"label\", palette=\"viridis\")\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Quantidade de pontos em cada clusters:\")\n",
    "    print(pd.Series(labels_clusters).value_counts())\n",
    "    \n",
    "    return df_result, n_clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos avaliar nossa função para os valores-padrão dos parâmetros do scikit-learn?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result, n_clusters = plot_dbscan(X_df,\n",
    "                                   eps = 0.5,\n",
    "                                   min_pts = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar que, para os valores-padrão dos parâmetros de entrada, obtemos apenas um grande cluster de dados - o que não nos auxilia. Sendo assim, o que acontece quando variamos os parâmetros?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0, _ = plot_dbscan(X_df, eps = 0.1, min_pts = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0.groupby('label')['label'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# variando o eps\n",
    "eps_values = np.linspace(0.1, 0.5, 5)\n",
    "n_clusters = []\n",
    "\n",
    "for eps in eps_values:\n",
    "    _, n = plot_dbscan(X_df, eps = eps, min_pts = 5)\n",
    "    n_clusters.append(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8,6))\n",
    "plt.plot(eps_values, n_clusters, marker = 'o')\n",
    "plt.title('Número de clusters em função de $\\epsilon$')\n",
    "plt.ylabel('Número de clusters')\n",
    "plt.xlabel('$\\epsilon$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conforme esperaríamos, à medida que aumentamos $\\epsilon$, conseguimos detectar menos agrupamentos com o DBSCAN (já que é necessária uma distância cada vez menor entre os pontos)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E se variarmos o mínimo de pontos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# variando o minPts\n",
    "minPts_values = range(1,10)\n",
    "n_clusters = []\n",
    "\n",
    "for minPts in minPts_values:\n",
    "    _, n = plot_dbscan(X_df, eps = 0.2, min_pts = minPts)\n",
    "    n_clusters.append(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8,6))\n",
    "plt.plot(minPts_values, n_clusters, marker = 'o')\n",
    "plt.title('Número de clusters em função do mínimo de pontos')\n",
    "plt.ylabel('Número de clusters')\n",
    "plt.xlabel('$minPts$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por fim, vamos identificar os outliers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result, _ = plot_dbscan(X_df, eps = 0.25, min_pts = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificando os outliers\n",
    "df_result.query(\"label==-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se quisermos, podemos remover os outliers para visualizar nossos clusters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.query(\"label != -1\").drop('label', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(data = df_result.query(\"label != -1\"),\n",
    "             x = 'x1',\n",
    "             y = 'x2',\n",
    "             hue = 'label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
